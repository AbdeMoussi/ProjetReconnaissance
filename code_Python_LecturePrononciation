import cv2
import pytesseract
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
import numpy as np
import time
import threading, queue
import pyttsx3
from collections import deque

# ===== Réglages OCR =====
LANG = "fra"     # mets "eng" si pas de pack FR
OEM  = 3             # 3 = LSTM
PSM  = 6             # 6: bloc, 7: ligne, 12: texte épars
CONF_MIN = 60        # confiance mini (0-100)
OCR_EVERY_N = 6      # OCR toutes les N frames

# ===== Réglages TTS =====
MIN_SPEAK_CHARS = 3   # ne pas prononcer si trop court (ex: 1-2 lettres isolées)
TTS_COOLDOWN = 0    # secondes mini entre 2 énoncés
SAY_MAX_CHARS = 160   # limite max par énoncé (confort)

# ---------- TTS non-bloquant ----------
class TTSWorker:
    def __init__(self, lang_hint="fra"):
        self.q = queue.Queue()
        self.th = threading.Thread(target=self._loop, daemon=True)
        self.engine = pyttsx3.init()
        # vitesse
        try: self.engine.setProperty('rate', 170)
        except Exception: pass
        # essayer une voix FR si souhaitée
        try:
            if "fr" in lang_hint:
                voices = self.engine.getProperty('voices')
                for v in voices:
                    name = (v.name or "").lower()
                    langs = "".join([str(x).lower() for x in getattr(v, "languages", [])])
                    if "fr" in name or "french" in name or "fr" in langs:
                        self.engine.setProperty('voice', v.id); break
        except Exception:
            pass
        self.muted = False
        self.running = True
        self.th.start()

    def _loop(self):
        while self.running:
            text = self.q.get()
            if text is None: break
            if not self.muted and text:
                try:
                    self.engine.stop()
                except Exception:
                    pass
                try:
                    self.engine.say(text)
                    self.engine.runAndWait()
                except Exception:
                    pass

    def speak(self, text: str):
        if not self.muted:
            self.q.put(text)

    def set_muted(self, m: bool):
        self.muted = m

    def close(self):
        self.running = False
        self.q.put(None)
        try:
            self.th.join(timeout=1.0)
        except Exception:
            pass

# ---------- OCR helpers ----------
def preprocess_for_ocr(frame_bgr):
    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.bilateralFilter(gray, 9, 75, 75)
    th = cv2.adaptiveThreshold(gray, 255,
                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, 31, 15)
    return th

def lines_from_tesseract_data(data, conf_min=60):
    """
    Regroupe mots -> lignes (ordre visuel).
    """
    n = len(data["text"])
    groups = {}
    for k in range(n):
        txt = data["text"][k]
        conf_raw = data["conf"][k]
        try: conf = float(conf_raw)
        except: conf = -1.0
        if not txt or not txt.strip() or conf < conf_min: 
            continue
        key = (data["block_num"][k], data["par_num"][k], data["line_num"][k])
        groups.setdefault(key, []).append((data["left"][k], txt.strip()))
    ordered = []
    for key in sorted(groups, key=lambda k: (k[0], k[1], k[2])):
        words = sorted(groups[key], key=lambda t: t[0])
        line = " ".join([w for _, w in words]).strip()
        if line:
            ordered.append(line)
    return ordered

def normalize_text(s: str) -> str:
    # nettoyage simple pour comparer
    return " ".join(s.strip().split()).lower()

# ---------- Main ----------
def run():
    global PSM, CONF_MIN

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        raise RuntimeError("Impossible d'ouvrir la webcam.")
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    tts = TTSWorker(lang_hint="fra" if "fra" in LANG else "eng")
    spoken_recent = deque(maxlen=30)  # mémoire des dernières phrases dites (normalisées)
    last_tts_ts = 0.0
    muted = False

    last_results = []
    i = 0
    prev_t = time.time()

    print("Contrôles: q=quitter | b=bloc(psm6) | s=scène(psm12) | l=ligne(psm7) | +/-=conf | m=mute | r=reset mémoire")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        display = frame.copy()
        proc = preprocess_for_ocr(frame)

        i += 1
        spoken_this_cycle = False

        if i % OCR_EVERY_N == 0:
            config = f"--oem {OEM} --psm {PSM}"
            data = pytesseract.image_to_data(proc, lang=LANG, config=config,
                                             output_type=pytesseract.Output.DICT)

            # boîtes pour overlay
            new_results = []
            n = len(data["text"])
            for k in range(n):
                txt = data["text"][k]
                conf_raw = data["conf"][k]
                try: conf = float(conf_raw)
                except: conf = -1.0
                if txt and txt.strip() and conf >= CONF_MIN:
                    x, y, w, h = data["left"][k], data["top"][k], data["width"][k], data["height"][k]
                    new_results.append((x, y, w, h, txt, conf))
            last_results = new_results

            # texte à prononcer : concat lignes (plus stable)
            lines = lines_from_tesseract_data(data, conf_min=CONF_MIN)
            to_say = " . ".join(lines).strip()
            norm = normalize_text(to_say)

            now = time.time()
            if (to_say 
                and len(norm) >= MIN_SPEAK_CHARS
                and norm not in spoken_recent
                and (now - last_tts_ts) >= TTS_COOLDOWN):
                
                # tronque si trop long
                say_text = to_say if len(to_say) <= SAY_MAX_CHARS else to_say[:SAY_MAX_CHARS] + " ..."
                tts.speak(say_text)
                spoken_recent.append(norm)
                last_tts_ts = now
                spoken_this_cycle = True

        # overlay OCR
        for (x, y, w, h, txt, conf) in last_results:
            cv2.rectangle(display, (x, y), (x + w, y + h), (0, 200, 0), 2)
            cv2.putText(display, f"{txt}",
                        (x, max(20, y - 6)), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                        (0, 0, 255), 2, cv2.LINE_AA)

        # HUD
        now = time.time()
        fps = 1.0 / (now - prev_t) if now > prev_t else 0.0
        prev_t = now
        mode = {6: "bloc", 12: "scene", 7: "ligne"}.get(PSM, str(PSM))
        status_tts = "PARLE" if spoken_this_cycle and not muted else ("MUTE" if muted else "...")
        hud = f"OCR {LANG} | PSM={PSM} ({mode}) | conf>={CONF_MIN} | {int(fps)} FPS | TTS:{status_tts}"
        cv2.putText(display, hud, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)
        cv2.putText(display, "b=bloc  s=scene  l=ligne  +/- conf  m=mute  r=reset  q=quit",
                    (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)

        cv2.imshow("Webcam OCR (Tesseract + TTS)", display)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('b'):
            PSM = 6
        elif key == ord('s'):
            PSM = 12
        elif key == ord('l'):
            PSM = 7
        elif key in (ord('+'), ord('=')):
            CONF_MIN = min(95, CONF_MIN + 5)
        elif key in (ord('-'), ord('_')):
            CONF_MIN = max(0,  CONF_MIN - 5)
        elif key == ord('m'):
            muted = not muted
            tts.set_muted(muted)
        elif key == ord('r'):
            spoken_recent.clear()

    cap.release()
    cv2.destroyAllWindows()
    tts.close()

if __name__ == "__main__":
    run()
